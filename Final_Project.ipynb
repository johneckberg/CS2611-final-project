{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fa303f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libs needed that aren't on the huggingface container \n",
    "# !pip install datasets --user\n",
    "# ! pip install evaluate --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed97268e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizerFast, TrainingArguments, Trainer, BertForSequenceClassification, \\\n",
    "    DataCollatorWithPadding\n",
    "from datasets import Dataset, load_dataset, DatasetDict\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "import torch\n",
    "import evaluate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d8834dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['texts', 'label', '__index_level_0__'],\n",
      "        num_rows: 21984\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['texts', 'label', '__index_level_0__'],\n",
      "        num_rows: 4397\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['texts', 'label', '__index_level_0__'],\n",
      "        num_rows: 1099\n",
      "    })\n",
      "})\n",
      "{'texts': 'Don`t let the sun catch you crying - Oh my.. so cool  http://tinyurl.com/cugy8c', 'label': 2, '__index_level_0__': 21558}\n"
     ]
    }
   ],
   "source": [
    "with open('Tweets.csv', mode='r') as file:\n",
    "    df = pd.read_csv(file, header=0)\n",
    "    df = df.drop(columns=['textID', 'selected_text'], axis=1)\n",
    "    df = df.rename(columns={\"text\": \"texts\", \"sentiment\": \"label\"})\n",
    "    df = df.dropna()\n",
    "\n",
    "df['label'] = df['label'].replace({\"neutral\":1, \"negative\":0, \"positive\":2})\n",
    "\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "train_test_valid = dataset.train_test_split(test_size=0.2)\n",
    "# this is apparently the best way to create a validation set\n",
    "# shuffle defaults to true\n",
    "test_valid = train_test_valid['test'].train_test_split(test_size=0.8)\n",
    "dataset = DatasetDict({\n",
    "    'train': train_test_valid['train'],\n",
    "    'test': test_valid['test'],\n",
    "    'valid': test_valid['train']})\n",
    "print(dataset)\n",
    "print(dataset[\"train\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "109fc043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dca58a2e93ae4bc8b767ddbbad1af024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/21984 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d48c33e2bbb407881399a7424ce3af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4397 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f11f7614d234a4ab1b18ea107a79e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1099 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "def tokenize_function(example):\n",
    "    \"\"\"\n",
    "    Tokenizes input embeddings using model tokenizer\"\"\"\n",
    "    return tokenizer(example[\"texts\"], truncation=True)\n",
    "\n",
    "metric1 = evaluate.load(\"precision\")\n",
    "metric2 = evaluate.load(\"recall\")\n",
    "    \n",
    "def compute_metrics(eval_preds):\n",
    "    \"\"\"\n",
    "    Computes eval metrics\"\"\"\n",
    "    \n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    precision = metric1.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    recall = metric2.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    \n",
    "\n",
    "    cm = confusion_matrix(predictions, labels)\n",
    "    cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    sns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=[\"negative\", \"neutral\", \"positive\"], yticklabels=[\"negative\", \"neutral\", \"positive\"])\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show(block=False)\n",
    "    return {\"precision\": precision, \"recall\": recall}\n",
    "\n",
    "# tokenize input sequences to subwords\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "tokenized_tweets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "\n",
    "# for batching\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cff7686e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9072238048595989}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.9072094609961338}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2903690040111542, 'eval_precision': {'precision': 0.9072238048595989}, 'eval_recall': {'recall': 0.9072094609961338}, 'eval_runtime': 7.5234, 'eval_samples_per_second': 584.445, 'eval_steps_per_second': 9.836}\n"
     ]
    }
   ],
   "source": [
    "# to load from checkpoint for eval; trainer class takes care of both training and eval.\n",
    "# pretty much just a general model wrapper\n",
    "model = BertForSequenceClassification.from_pretrained('results/')\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_eval_batch_size=30\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    tokenizer=tokenizer,\n",
    "    eval_dataset=tokenized_tweets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# speeds up testing by turning off backprop objects\n",
    "with torch.no_grad():\n",
    "    eval_results = trainer.evaluate()\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "925e6cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['texts', 'label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 21984\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['texts', 'label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 4397\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['texts', 'label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 1099\n",
      "    })\n",
      "})\n",
      "True\n",
      "cuda\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4122' max='4122' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4122/4122 12:14, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.685800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.542400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.488300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.405800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.336700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.274900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.290700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "# to train model; see https://huggingface.co/docs/transformers/model_doc/bert#transformers.BertForSequenceClassification\n",
    "import torch\n",
    "print(tokenized_tweets)\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(torch.cuda.device_count())\n",
    "\n",
    "# init model:\n",
    "# takes in a string and pulls the model from huggingface\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
    "\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01)\n",
    "\n",
    "# train\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_tweets[\"train\"],\n",
    "    eval_dataset=tokenized_tweets[\"valid\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ea87265",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 2\u001b[0m     eval_results \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(eval_results)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py:2993\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2990\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   2992\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 2993\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2994\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2995\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2996\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   2997\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   2998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2999\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3000\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3001\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3003\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py:3281\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3277\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(\n\u001b[1;32m   3278\u001b[0m             EvalPrediction(predictions\u001b[38;5;241m=\u001b[39mall_preds, label_ids\u001b[38;5;241m=\u001b[39mall_labels, inputs\u001b[38;5;241m=\u001b[39mall_inputs)\n\u001b[1;32m   3279\u001b[0m         )\n\u001b[1;32m   3280\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3281\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEvalPrediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3282\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3283\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[0;32mIn[3], line 18\u001b[0m, in \u001b[0;36mcompute_metrics\u001b[0;34m(eval_preds)\u001b[0m\n\u001b[1;32m     16\u001b[0m logits, labels \u001b[38;5;241m=\u001b[39m eval_preds\n\u001b[1;32m     17\u001b[0m predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(logits, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m precision \u001b[38;5;241m=\u001b[39m \u001b[43mmetric1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreferences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m recall \u001b[38;5;241m=\u001b[39m metric2\u001b[38;5;241m.\u001b[39mcompute(predictions\u001b[38;5;241m=\u001b[39mpredictions, references\u001b[38;5;241m=\u001b[39mlabels)\n\u001b[1;32m     22\u001b[0m conf_matrix \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mconfusion_matrix(predictions,labels)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/evaluate/module.py:462\u001b[0m, in \u001b[0;36mEvaluationModule.compute\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {input_name: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[input_name] \u001b[38;5;28;01mfor\u001b[39;00m input_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_names()}\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m temp_seed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed):\n\u001b[0;32m--> 462\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcompute_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_writer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--precision/4e7f439a346715f68500ce6f2be82bf3272abd3f20bdafd203a2c4f85b61dd5f/precision.py:136\u001b[0m, in \u001b[0;36mPrecision._compute\u001b[0;34m(self, predictions, references, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compute\u001b[39m(\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    128\u001b[0m     predictions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    134\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    135\u001b[0m ):\n\u001b[0;32m--> 136\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreferences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(score) \u001b[38;5;28;01mif\u001b[39;00m score\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m score}\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:63\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     66\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[1;32m     67\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args],\n\u001b[1;32m     68\u001b[0m                                  args[\u001b[38;5;241m-\u001b[39mextra_args:])]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1656\u001b[0m, in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1546\u001b[0m \u001b[38;5;129m@_deprecate_positional_args\u001b[39m\n\u001b[1;32m   1547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprecision_score\u001b[39m(y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1548\u001b[0m                     average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1549\u001b[0m                     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1550\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute the precision.\u001b[39;00m\n\u001b[1;32m   1551\u001b[0m \n\u001b[1;32m   1552\u001b[0m \u001b[38;5;124;03m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1654\u001b[0m \n\u001b[1;32m   1655\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1656\u001b[0m     p, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1657\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1658\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1659\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1660\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprecision\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1661\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1663\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:63\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     66\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[1;32m     67\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args],\n\u001b[1;32m     68\u001b[0m                                  args[\u001b[38;5;241m-\u001b[39mextra_args:])]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1464\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m beta \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1463\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeta should be >=0 in the F-beta score\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1464\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1465\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1467\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1468\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1294\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1292\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1293\u001b[0m             average_options\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget is \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m but average=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Please \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1295\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoose another average setting, one of \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1296\u001b[0m                          \u001b[38;5;241m%\u001b[39m (y_type, average_options))\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pos_label \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1298\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote that pos_label (set to \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) is ignored when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1299\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage != \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m). You may use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1300\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels=[pos_label] to specify a single positive class.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1301\u001b[0m                   \u001b[38;5;241m%\u001b[39m (pos_label, average), \u001b[38;5;167;01mUserWarning\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    eval_results = trainer.evaluate(tokenized_tweets[\"test\"])\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60d1cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
